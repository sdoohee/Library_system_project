{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install essential python packages","metadata":{"pycharm":{"name":"#%% md\n"},"id":"cMxv4wfrwPBL"}},{"cell_type":"code","source":"!pip install -q timm albumentations wandb","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-output":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","pycharm":{"name":"#%%\n"},"id":"Pf7qu_QywPBO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install catalyst","metadata":{"id":"3BroIBO4Gi4l","outputId":"65ce83cb-e964-4842-a083-82a5ff467190"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import essential python packages","metadata":{"pycharm":{"name":"#%% md\n"},"id":"wgLCw5TtwPBQ"}},{"cell_type":"code","source":"from glob import glob\nfrom sklearn.model_selection import GroupKFold\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport os\nimport time\nfrom datetime import datetime\nimport random\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport albumentations as A\nimport matplotlib.pyplot as plt\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SequentialSampler\nimport wandb\nimport timm\nimport shutil\nfrom catalyst.data.sampler import BalanceClassSampler\nimport warnings\n\nwarnings.filterwarnings(action='ignore')","metadata":{"pycharm":{"name":"#%%\n"},"id":"xJRsftcewPBQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyper-parameter setting","metadata":{"pycharm":{"name":"#%% md\n"},"id":"L4EgAqGNwPBR"}},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/gdrive', force_remount=True)","metadata":{"id":"mTWUsTh7HBdH","outputId":"7780d686-8db6-4334-a02a-2d7c54fafe8c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#압축파일 그대로 올리는 경우 해당 경로에 압축해제\n!unzip -qq '/gdrive/My Drive/22년 조교 업무/2학기_인공지능/2022_AI_dataset.zip'","metadata":{"id":"z0Rsr-RkHaur","outputId":"8191272e-5c96-467b-9b73-d945cc8bec1b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args = {\n    'model_name': 'tf_efficientnet_b0_ns',  # 신경망 구조\n    'lr': 1e-3,  # 학습률\n    'weight_decay': 1e-4,  # 가중치 감쇠\n    'drop_rate': 0.2,  # 학습 시 dropout 비율\n    'image_size': 256,  # 이미지 크기\n    'num_epochs': 1,  # 학습 반복수\n    'batch_size': 16,  # 미니배치 크기\n    'num_classes': 2,  # 판별할 클래스 개수\n    'num_folds': 5,  # 데이터셋 분할 fold 개수\n    'val_fold': 0,  # 검증용 fold 선택\n    'seed': 42,  # 랜덤 seed 설정\n    'log_step': 50,  # log 남길 iteration 반복 수\n    'model_save_step': 5,  # model 저장할 epoch 반복 수\n    'workspace_path': '/content',  # 작업 위치\n    'checkpoint_dir': './checkpoints',  # 모델 저장 디렉토리\n    'pretrained_name': 'tf_efficientnet_b0_ns_model_best.pth',  # 학습한 모델 파일이름 (.pth까지 붙이기)\n}\n\nTRAIN_DATA_ROOT_PATH = os.path.join(args['workspace_path'], 'train')\nTEST_DATA_ROOT_PATH = os.path.join(args['workspace_path'], 'test')","metadata":{"pycharm":{"name":"#%%\n"},"id":"HC4NSdFKwPBR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n\nseed_everything(43)","metadata":{"pycharm":{"name":"#%%\n"},"id":"4GLRue7MwPBS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"pycharm":{"name":"#%%\n"},"id":"R77jC5eywPBT","outputId":"48cee330-054f-4e94-d989-04abea90be14"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.init(project=\"2022_AI\", entity=\"jeo514\")\nwandb.run.name = 'steganalysis(classification)'","metadata":{"pycharm":{"name":"#%%\n"},"id":"YKmDCVO-wPBU","outputId":"55e8ab1c-20cc-4725-cbda-f64115fb77d4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GroupKFold splitting","metadata":{"pycharm":{"name":"#%% md\n"},"id":"qS6xy7cVwPBV"}},{"cell_type":"code","source":"dataset = []\n\nfor label, kind in enumerate(['cover', 'stego']):\n    for path in glob(f'{TRAIN_DATA_ROOT_PATH}/{kind}/*.png', recursive=True):\n        dataset.append({\n            'kind': kind,\n            'image_name': path.replace('\\\\', '/').split('/')[-1],\n            'label': label\n        })\n\nrandom.shuffle(dataset)\ndataset = pd.DataFrame(dataset)\n\ngkf = GroupKFold(n_splits=args['num_folds'])\n\ndataset.loc[:, 'fold'] = 0\nfor fold_number, (train_index, val_index) in enumerate(gkf.split(X=dataset.index, y=dataset['label'], groups=dataset['image_name'])):\n    dataset.loc[dataset.iloc[val_index].index, 'fold'] = fold_number","metadata":{"pycharm":{"name":"#%%\n"},"id":"Rh-7Z_DrwPBV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"pycharm":{"name":"#%%\n"},"id":"quNNcqc9wPBW","outputId":"9ac00eaa-6279-4bf6-e376-607e030c650c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"pycharm":{"name":"#%% md\n"},"id":"HJKh0qPjwPBW"}},{"cell_type":"code","source":"class DatasetRetriever(Dataset):\n    def __init__(self, kinds, image_names, labels, transforms=None):\n        super().__init__()\n        self.kinds = kinds\n        self.image_names = image_names\n        self.labels = labels\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n        kind, image_name, label = self.kinds[index], self.image_names[index], self.labels[index]\n        image_path = f'{TRAIN_DATA_ROOT_PATH}/{kind}/{image_name}'.replace('\\\\', '/')\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image /= 255.0\n        if self.transforms:\n            sample = {'image': image}\n            sample = self.transforms(**sample)\n            image = sample['image']\n            \n        return image, label\n\n    def __len__(self) -> int:\n        return self.image_names.shape[0]\n\n    def get_labels(self):\n        return list(self.labels)","metadata":{"pycharm":{"name":"#%%\n"},"id":"osR1URoZwPBX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Simple Augmentations: Flips","metadata":{"pycharm":{"name":"#%% md\n"},"id":"Vt47hWkPwPBX"}},{"cell_type":"code","source":"def get_train_transforms():\n    return A.Compose([\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.5),\n            ToTensorV2(p=1.0),\n        ], p=1.0)\n\ndef get_valid_transforms():\n    return A.Compose([\n            ToTensorV2(p=1.0),\n        ], p=1.0)","metadata":{"pycharm":{"name":"#%%\n"},"id":"nwrUau3WwPBX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = DatasetRetriever(\n    kinds=dataset[dataset['fold'] != args['val_fold']].kind.values,\n    image_names=dataset[dataset['fold'] != args['val_fold']].image_name.values,\n    labels=dataset[dataset['fold'] != args['val_fold']].label.values,\n    transforms=get_train_transforms(),\n)\n\nvalidation_dataset = DatasetRetriever(\n    kinds=dataset[dataset['fold'] == args['val_fold']].kind.values,\n    image_names=dataset[dataset['fold'] == args['val_fold']].image_name.values,\n    labels=dataset[dataset['fold'] == args['val_fold']].label.values,\n    transforms=get_valid_transforms(),\n)","metadata":{"pycharm":{"name":"#%%\n"},"id":"_DqqvgLfwPBY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, target = train_dataset[0]\nnumpy_image = image.permute(1,2,0).cpu().numpy()\n\nfig, ax = plt.subplots(1, 1, figsize=(16, 8))\n\nax.set_axis_off()\nax.imshow(numpy_image)","metadata":{"pycharm":{"name":"#%%\n"},"id":"HTu-jWVvwPBY","outputId":"861b3d37-e866-4a2f-dceb-92a6b947f8aa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cover_image = cv2.imread(os.path.join(TRAIN_DATA_ROOT_PATH, 'cover', '00001.png'), cv2.IMREAD_COLOR)\ncover_image = cv2.cvtColor(cover_image, cv2.COLOR_BGR2RGB)\nstego_image = cv2.imread(os.path.join(TRAIN_DATA_ROOT_PATH, 'stego', '00001.png'), cv2.IMREAD_COLOR)\nstego_image = cv2.cvtColor(stego_image, cv2.COLOR_BGR2RGB)\ndifference = np.abs(cover_image - stego_image)\n\nfig, ax = plt.subplots(1, 1, figsize=(16, 8))\n\nax.set_axis_off()\nim = ax.imshow(difference, vmin=0, vmax=255)\nfig.colorbar(im)\nplt.show()","metadata":{"pycharm":{"name":"#%%\n"},"id":"hTsGkVnHwPBY","outputId":"c72416f3-5e1f-4580-9db2-d94936ae6616"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        sampler=BalanceClassSampler(labels=train_dataset.get_labels(), mode=\"downsampling\"),\n        batch_size=args['batch_size'],\n        pin_memory=False,\n        drop_last=True,\n    )\nval_loader = torch.utils.data.DataLoader(\n        validation_dataset,\n        batch_size=args['batch_size'],\n        shuffle=False,\n        sampler=SequentialSampler(validation_dataset),\n        pin_memory=False,\n    )","metadata":{"pycharm":{"name":"#%%\n"},"id":"5l4K_aOawPBZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Metrics","metadata":{"pycharm":{"name":"#%% md\n"},"id":"5BtVtPACwPBZ"}},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef accuracy(output, label, topk=(1,)):\n    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n    maxk = max(topk)\n    batch_size = label.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)  # prediction: select k maximum at each output\n    pred = pred.t()\n    correct = pred.eq(label.view(1, -1).expand_as(pred))\n    acc = correct.view(-1).float().sum(0, keepdim=True).mul_(100.0 / batch_size)  # acc = num of equivalcencs / target_size\n    result = to_np(correct.view(-1))\n\n    return acc, result\n\ndef to_np(x):\n    return x.detach().cpu().data.numpy()","metadata":{"pycharm":{"name":"#%%\n"},"id":"NJlPb99wwPBZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss","metadata":{"pycharm":{"name":"#%% md\n"},"id":"b2ri0FfjwPBZ"}},{"cell_type":"code","source":"loss_func = nn.CrossEntropyLoss().to(device)","metadata":{"pycharm":{"name":"#%%\n"},"id":"zk3WoNrjwPBZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"pycharm":{"name":"#%% md\n"},"id":"FDX-pu24wPBa"}},{"cell_type":"code","source":"!mkdir './checkpoints'\ndef get_net():\n    net = timm.create_model(args['model_name'], num_classes=args['num_classes'], pretrained=True)\n    return net\n\nmodel = get_net().to(device)","metadata":{"pycharm":{"name":"#%%\n"},"id":"8lbO7M9PwPBa","outputId":"dc3f0bad-2056-44a5-975e-26bf97f57eeb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save & Load pretrained model","metadata":{"pycharm":{"name":"#%% md\n"},"id":"F0TX1FtrwPBa"}},{"cell_type":"code","source":"def save_checkpoint(model, optimizer, best_acc, checkpoint_path, model_name, is_best, epoch):\n    state = {\n        'model': model.state_dict(),\n        'optimizer': optimizer.state_dict(),\n        'best_acc': best_acc,\n        'epoch': epoch\n    }\n\n    if not os.path.exists(checkpoint_path):\n        os.makedirs(checkpoint_path)\n\n    filename = os.path.join(checkpoint_path, f'{model_name}_model_epoch_{state[\"epoch\"]}.pth')\n    torch.save(state, filename)\n    if is_best:\n        shutil.copyfile(filename, os.path.join(checkpoint_path, f'{model_name}_model_best.pth'))\n\n\ndef load_checkpoint(model, optimizer, pretrained_path, device):\n    state = torch.load(pretrained_path, map_location=device)\n    model.load_state_dict(state['model'])\n    best_acc = state['best_acc']\n    epoch = state['epoch']\n    print(f'\\t## loaded trained models (epoch: {epoch})\\n')\n    return model, optimizer, best_acc, epoch","metadata":{"pycharm":{"name":"#%%\n"},"id":"mEL1MdA0wPBa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optimizer","metadata":{"pycharm":{"name":"#%% md\n"},"id":"WlT4krw9wPBa"}},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(),\n                              lr=args['lr'], betas=(0.9, 0.999),\n                              weight_decay=args['weight_decay'])","metadata":{"pycharm":{"name":"#%%\n"},"id":"yrR7UTVZwPBa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load pretrained model","metadata":{"pycharm":{"name":"#%% md\n"},"id":"4r5ntzVKwPBb"}},{"cell_type":"code","source":"# if args['pretrained_name']:\n#     pretrained_path = os.path.join(args['checkpoint_dir'], args['pretrained_name'])\n#     model, optimizer, best_acc, initial_epoch = load_checkpoint(model, optimizer, pretrained_path, device)\n# else:\n#     initial_epoch = 0\n#     best_acc = 0\ninitial_epoch = 0\nbest_acc = 0","metadata":{"pycharm":{"name":"#%%\n"},"id":"coqosP26wPBb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{"pycharm":{"name":"#%% md\n"},"id":"ryDdC0EmwPBb"}},{"cell_type":"code","source":"def train(train_loader, model, *args):\n    # switch to train mode\n    model.train()\n\n    with torch.enable_grad():\n        train_acc, train_loss = iteration('train', train_loader, model, *args)\n\n    return train_acc, train_loss","metadata":{"pycharm":{"name":"#%%\n"},"id":"9h_BvssLwPBb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validate","metadata":{"pycharm":{"name":"#%% md\n"},"id":"W520PA4dwPBb"}},{"cell_type":"code","source":"def validate(val_loader, model, *args):\n    # switch to eval mode\n    model.eval()\n\n    with torch.no_grad():\n        val_acc, val_loss = iteration('val', val_loader, model, *args)\n\n    return val_acc, val_loss","metadata":{"pycharm":{"name":"#%%\n"},"id":"aEU4-xKLwPBc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Iteration","metadata":{"pycharm":{"name":"#%% md\n"},"id":"-jw7EMMDwPBc"}},{"cell_type":"code","source":"def iteration(mode, data_loader, model, optimizer, loss_func, epoch):\n    am_batch_time = AverageMeter()\n    am_data_time = AverageMeter()\n    am_loss = AverageMeter()\n    am_acc = AverageMeter()\n\n    end = time.time()\n    num_batch = np.ceil(len(data_loader)).astype(np.int32)\n\n    for i, (input_img, target) in enumerate(data_loader):\n        # measure data loading time\n        am_data_time.update(time.time() - end)\n\n        input_img = input_img.to(device)\n        target = target.to(device)\n\n        # feed-forward\n        output = model(input_img)   # two output\n\n        # calculate loss\n        output = torch.nan_to_num(output)\n        loss = loss_func(output, target)\n        am_loss.update(loss.item(), input_img.size(0))\n\n        # calculate accuracy\n        class_prob = F.softmax(output, dim=1)\n        class_acc, _ = accuracy(class_prob, target)\n        am_acc.update(class_acc.item(), input_img.size(0))\n\n        # compute gradient and do SGD step\n        if mode == 'train':\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n        # measure elapsed time\n        am_batch_time.update(time.time() - end)\n        end = time.time()\n        if (i + 1) % args['log_step'] == 0:\n            print('Epoch: [{0}/{1}][{2}/{3}]\\t'\n                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n                  'Loss {loss.val:.4f} ({loss.avg:.4f}) \\t'\n                  'Accuracy {acc.val:.4f} ({acc.avg:.4f})'\n                  .format(epoch + 1, args['num_epochs'], i + 1, num_batch, batch_time=am_batch_time,\n                          data_time=am_data_time, loss=am_loss, acc=am_acc))\n\n    return am_acc.avg, am_loss.avg","metadata":{"pycharm":{"name":"#%%\n"},"id":"jSZvIM1jwPBc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pipeline: train, validate, log, and save","metadata":{"pycharm":{"name":"#%% md\n"},"id":"2VNZbS9FwPBc"}},{"cell_type":"code","source":"min_loss = 1000\nfor epoch in range(initial_epoch, args['num_epochs']):\n    # train for one epoch\n    print('# Training')\n    train_acc, train_loss = train(train_loader, model, optimizer, loss_func, epoch)\n    wandb.log({'train_acc': train_acc, 'train_loss': train_loss})\n\n    # evaluate on validation set\n    print('# Validation')\n    val_acc, val_loss = validate(val_loader, model, optimizer, loss_func, epoch)\n    wandb.log({'val_acc': val_acc, 'val_loss':val_loss})\n\n    is_best = val_acc > best_acc\n    best_acc = max(val_acc, best_acc)\n    min_loss = min(val_loss, min_loss)\n\n    if is_best or (epoch + 1) % args['model_save_step'] == 0:\n        save_checkpoint(model, optimizer, best_acc, args['checkpoint_dir'], args['model_name'], is_best, epoch + 1)","metadata":{"pycharm":{"name":"#%%\n","is_executing":true},"id":"ll12nLilwPBc","outputId":"279cf69e-f906-4bb1-e85e-2e23669b2e58"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{"pycharm":{"name":"#%% md\n"},"id":"wq5RRpL4wPBd"}},{"cell_type":"code","source":"pretrained_path = os.path.join(args['checkpoint_dir'], args['pretrained_name'])\nmodel, _, _, _ = load_checkpoint(model, optimizer, pretrained_path, device)\nmodel.eval()","metadata":{"pycharm":{"name":"#%%\n","is_executing":true},"id":"eq7TnlTkwPBd","outputId":"147d8563-d84b-4e04-d0e4-eb0c5ab9731d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DatasetSubmissionRetriever(Dataset):\n    def __init__(self, image_names, transforms=None):\n        super().__init__()\n        self.image_names = image_names\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n        image_name = self.image_names[index]\n        image_path = f'{TEST_DATA_ROOT_PATH}/{image_name}'\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image /= 255.0\n        if self.transforms:\n            sample = {'image': image}\n            sample = self.transforms(**sample)\n            image = sample['image']\n\n        return image_name, image\n\n    def __len__(self) -> int:\n        return self.image_names.shape[0]","metadata":{"pycharm":{"name":"#%%\n","is_executing":true},"id":"egVMBrOZwPBd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = DatasetSubmissionRetriever(\n    image_names=np.array([path.replace('\\\\', '/').split('/')[-1] for path in glob('./test/*.png')]),\n    transforms=get_valid_transforms(),\n)\n\n\ntest_loader = DataLoader(\n    dataset,\n    batch_size=args['batch_size'],\n    shuffle=False,\n    drop_last=False,\n)","metadata":{"pycharm":{"name":"#%%\n","is_executing":true},"id":"VB-UNhdzwPBd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_result = pd.DataFrame(columns=['id', 'label'])\nfor step, (image_names, images) in enumerate(test_loader):\n    print(step, end='\\r')\n    images = images.to(device)\n    output = model(images)\n    class_prob = F.softmax(output, dim=1)\n    _, class_pred = output.topk(1, 1, True, True)  # prediction: select k maximum at each output\n    label = class_pred.view(-1).detach().cpu().numpy()\n    df_curr = pd.DataFrame({\n        'id': image_names,\n        'label': label\n    })\n    df_result = pd.concat([df_result, df_curr], axis=0, ignore_index=True)","metadata":{"pycharm":{"name":"#%%\n","is_executing":true},"id":"q8xWbIlMwPBd","outputId":"5c739ab1-0668-406a-b172-190dc6253fa2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"current_time = datetime.now().strftime(r'%y-%m-%d_%H-%M-%S')\ndf_result.to_csv(f'submission_{current_time}.csv', index=False)\ndf_result.head()","metadata":{"pycharm":{"name":"#%%\n","is_executing":true},"id":"EyPDMB2AwPBe","outputId":"5df504f4-1930-407c-9ac5-da5cc0abae20"},"execution_count":null,"outputs":[]}]}